#!/usr/bin/env python3
"""
ç®€åŒ–çš„è®­ç»ƒæµ‹è¯• - éªŒè¯æ•´ä¸ªæµç¨‹
"""

import os
import sys
import json
from pathlib import Path

def test_training_setup():
    """æµ‹è¯•è®­ç»ƒè®¾ç½®"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒè®¾ç½®æµ‹è¯•...")
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    try:
        import torch
        import transformers
        import peft
        from datasets import load_from_disk
        print("âœ… æ‰€æœ‰å¿…è¦æ¨¡å—å·²å¯¼å…¥")
        print(f"   PyTorch: {torch.__version__}")
        print(f"   Transformers: {transformers.__version__}")
        print(f"   PEFT: {peft.__version__}")
        print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # 2. æ£€æŸ¥æ•°æ®
    data_path = Path("data/processed/test_data")
    if not data_path.exists():
        print("âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨")
        return False
    
    print("âœ… è®­ç»ƒæ•°æ®å­˜åœ¨")
    
    # 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = Path("configs/quick_test.yaml")
    if not config_path.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    print("âœ… é…ç½®æ–‡ä»¶å­˜åœ¨")
    
    # 4. æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹
    print("\nğŸ”§ æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹...")
    
    try:
        # åŠ è½½æ•°æ®
        dataset = load_from_disk(data_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(dataset)} æ ·æœ¬")
        
        # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼ˆè½»é‡çº§æµ‹è¯•ï¼‰
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        model_name = "distilgpt2"
        print(f"ğŸ”§ åŠ è½½æ¨¡å‹: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        tokenizer.pad_token = tokenizer.eos_token
        print("âœ… åˆ†è¯å™¨åŠ è½½æˆåŠŸ")
        
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # é…ç½®LoRA
        from peft import LoraConfig, get_peft_model
        
        lora_config = LoraConfig(
            r=8,
            lora_alpha=16,
            target_modules=["c_attn", "c_proj"],
            lora_dropout=0.1,
            bias="none",
            task_type="CAUSAL_LM"
        )
        
        model = get_peft_model(model, lora_config)
        print("âœ… LoRAé…ç½®æˆåŠŸ")
        
        # æ˜¾ç¤ºå‚æ•°ä¿¡æ¯
        model.print_trainable_parameters()
        
        # æµ‹è¯•æ¨ç†
        print("\nğŸ§ª æµ‹è¯•åŸºç¡€æ¨ç†...")
        test_input = "è¯·ä»‹ç»äººå·¥æ™ºèƒ½"
        inputs = tokenizer(test_input, return_tensors="pt")
        
        model.eval()
        with torch.no_grad():
            outputs = model.generate(
                inputs["input_ids"],
                max_length=50,
                num_return_sequences=1,
                temperature=0.7,
                pad_token_id=tokenizer.eos_token_id
            )
        
        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"âœ… ç”Ÿæˆæ–‡æœ¬: {generated_text}")
        
        print("\nğŸ‰ è®­ç»ƒè®¾ç½®æµ‹è¯•å®Œå…¨æˆåŠŸï¼")
        print("ğŸ“‹ ç³»ç»Ÿå°±ç»ªï¼Œå¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒ")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè®¾ç½®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_training_log():
    """åˆ›å»ºè®­ç»ƒæ—¥å¿—æ–‡ä»¶"""
    import datetime
    import torch
    
    current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    cuda_status = 'CUDAå¯ç”¨' if torch.cuda.is_available() else 'CPUæ¨¡å¼'
    
    log_content = f"""# è®­ç»ƒæ—¥å¿—

## ç¯å¢ƒé…ç½®
- æ—¶é—´: {current_time}
- ç³»ç»Ÿ: Windows
- GPU: {cuda_status}
- Python: {sys.version}

## è®­ç»ƒè®¾ç½®
- æ¨¡å‹: DistilGPT2
- LoRAé…ç½®: r=8, alpha=16
- æ•°æ®: ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†
- æ‰¹æ¬¡å¤§å°: 1
- å­¦ä¹ ç‡: 2e-4

## è®­ç»ƒçŠ¶æ€
âœ… ç¯å¢ƒéªŒè¯é€šè¿‡
âœ… æ•°æ®æ ¼å¼æ­£ç¡®
âœ… æ¨¡å‹é…ç½®æˆåŠŸ
ğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ...
"""
    
    log_dir = Path("results/logs")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    with open(log_dir / "training.log", 'w', encoding='utf-8') as f:
        f.write(log_content)
    
    print(f"ğŸ“ è®­ç»ƒæ—¥å¿—å·²åˆ›å»º: {log_dir / 'training.log'}")

if __name__ == "__main__":
    print("ğŸ” å¼€å§‹ç»¼åˆè®­ç»ƒæµ‹è¯•...")
    
    if test_training_setup():
        create_training_log()
        print("\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. è¿è¡Œå®Œæ•´è®­ç»ƒ: python src/train.py --config configs/quick_test.yaml")
        print("2. å¯åŠ¨Webç•Œé¢: python demo/gradio_demo.py")
        print("3. æŸ¥çœ‹æ—¥å¿—: cat results/logs/training.log")
        print("\nâœ¨ æ‚¨çš„æ¡†æ¶å·²ç»100%å°±ç»ªï¼")
    else:
        print("\nâŒ è¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•")