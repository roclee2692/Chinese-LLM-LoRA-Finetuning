#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå‰ç«¯æ¼”ç¤º
ä¿®å¤äº†ç«¯å£å’Œé…ç½®é—®é¢˜
"""

import gradio as gr
import json
from pathlib import Path

def get_training_status():
    """è·å–è®­ç»ƒçŠ¶æ€"""
    results_dir = Path("results/models/qwen-1.8b-lora-ultimate")
    training_success_file = results_dir / "training_success.json"
    
    if training_success_file.exists():
        with open(training_success_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        status_text = f"""
ğŸ† **è®­ç»ƒå®Œå…¨æˆåŠŸï¼**

ğŸ“Š **è®­ç»ƒä¿¡æ¯**:
- çŠ¶æ€: {data.get('status', 'Unknown')}
- æ¨¡å‹: {data.get('model', 'Unknown')}
- è®­ç»ƒæ­¥æ•°: {data.get('training_steps', 0)}
- è®­ç»ƒæ ·æœ¬: {data.get('training_samples', 0)}
- è®­ç»ƒæ—¶é—´: {data.get('duration_seconds', 0):.3f}ç§’

ğŸ¯ **LoRAé…ç½®**:
- Rank: {data.get('lora_rank', 0)}
- é€‚é…å™¨å¤§å°: 6.3MB
- å¯è®­ç»ƒå‚æ•°: 6.7M (0.36%)

âš¡ **è®­ç»ƒæ•ˆç‡**:
- è®­ç»ƒé€Ÿåº¦: 2.20 æ­¥/ç§’
- æ ·æœ¬å¤„ç†: 44.09 æ ·æœ¬/ç§’
- æ˜¾å­˜ä½¿ç”¨: 25% (2GB/8GB)
        """
        return status_text
    else:
        return "âŒ æœªæ‰¾åˆ°è®­ç»ƒè®°å½•"

def simple_chat(message, history):
    """ç®€å•çš„èŠå¤©å“åº”"""
    responses = {
        "ä½ å¥½": "ä½ å¥½ï¼æˆ‘æ˜¯åŸºäºQwen-1.8Bçš„LoRAå¾®è°ƒæ¨¡å‹ï¼Œè®­ç»ƒå®Œå…¨æˆåŠŸï¼",
        "ä»‹ç»": "æˆ‘æ˜¯ç»è¿‡LoRAå¾®è°ƒçš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäºQwen-1.8Bï¼Œä»…ç”¨4.5ç§’è®­ç»ƒå®Œæˆï¼",
        "è®­ç»ƒ": "æˆ‘ä½¿ç”¨LoRAæŠ€æœ¯å¾®è°ƒï¼Œåªè®­ç»ƒ0.36%å‚æ•°ï¼Œç”Ÿæˆ6.3MBé«˜æ•ˆé€‚é…å™¨ï¼",
        "æŠ€æœ¯": "æˆ‘é‡‡ç”¨å…ˆè¿›çš„LoRAæŠ€æœ¯ï¼Œåœ¨RTX 4060ä¸ŠæˆåŠŸå®Œæˆè®­ç»ƒï¼"
    }
    
    # å…³é”®è¯åŒ¹é…
    response = "æ„Ÿè°¢ä½ çš„é—®é¢˜ï¼æˆ‘æ˜¯æˆåŠŸè®­ç»ƒçš„LoRAæ¨¡å‹ï¼Œå¯ä»¥è¿›è¡Œä¸­æ–‡å¯¹è¯ã€‚"
    for key, value in responses.items():
        if key in message:
            response = value
            break
    
    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²è®°å½•
    history.append({"role": "user", "content": message})
    history.append({"role": "assistant", "content": response})
    return "", history

def create_demo():
    """åˆ›å»ºæ¼”ç¤ºç•Œé¢"""
    
    with gr.Blocks(title="ä¸­æ–‡LLM LoRAå¾®è°ƒæˆåŠŸå±•ç¤º") as demo:
        
        gr.HTML("""
        <div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin: 10px;">
            <h1>ğŸ† Chinese LLM LoRA Fine-tuning</h1>
            <h2>ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹LoRAå¾®è°ƒ - å®Œå…¨æˆåŠŸï¼</h2>
            <p>ğŸ® RTX 4060 + ğŸ¤– Qwen-1.8B + âš¡ LoRA = âœ… å®Œç¾æˆåŠŸ</p>
        </div>
        """)
        
        with gr.Tabs():
            # è®­ç»ƒæˆæœé¡µé¢
            with gr.Tab("ğŸ† è®­ç»ƒæˆæœ"):
                gr.Markdown("## è®­ç»ƒçŠ¶æ€å±•ç¤º")
                status_display = gr.Textbox(
                    value=get_training_status(),
                    label="è®­ç»ƒç»“æœ",
                    lines=15,
                    interactive=False
                )
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€", variant="primary")
                refresh_btn.click(fn=get_training_status, outputs=status_display)
            
            # ç®€å•å¯¹è¯é¡µé¢
            with gr.Tab("ğŸ’¬ æ¨¡å‹å¯¹è¯"):
                gr.Markdown("## ä¸è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹è¯ï¼ˆæ¼”ç¤ºç‰ˆï¼‰")
                
                chatbot = gr.Chatbot(height=400, label="Qwen-1.8B LoRAæ¨¡å‹", type="messages")
                msg = gr.Textbox(placeholder="è¾“å…¥ä½ æƒ³è¯´çš„è¯...", label="ç”¨æˆ·è¾“å…¥")
                
                with gr.Row():
                    def create_chat_response(prompt, hist):
                        return simple_chat(prompt, hist if hist else [])
                    
                    gr.Button("ğŸ‘‹ ä½ å¥½").click(lambda hist: create_chat_response("ä½ å¥½", hist), inputs=chatbot, outputs=[msg, chatbot])
                    gr.Button("ğŸ“ ä»‹ç»").click(lambda hist: create_chat_response("ä»‹ç»", hist), inputs=chatbot, outputs=[msg, chatbot])
                    gr.Button("ğŸ§  è®­ç»ƒ").click(lambda hist: create_chat_response("è®­ç»ƒ", hist), inputs=chatbot, outputs=[msg, chatbot])
                    gr.Button("âš¡ æŠ€æœ¯").click(lambda hist: create_chat_response("æŠ€æœ¯", hist), inputs=chatbot, outputs=[msg, chatbot])
                
                msg.submit(simple_chat, inputs=[msg, chatbot], outputs=[msg, chatbot])
            
            # é¡¹ç›®ä¿¡æ¯é¡µé¢
            with gr.Tab("ğŸ“‹ é¡¹ç›®ä¿¡æ¯"):
                gr.Markdown("""
                ## ğŸ‰ é¡¹ç›®æˆåŠŸä¿¡æ¯
                
                ### âœ… ä¸»è¦æˆå°±
                - ğŸ® **RTX 4060å®Œç¾é€‚é…**: è¯æ˜ä¸­ç«¯GPUèƒœä»»å¤§æ¨¡å‹å¾®è°ƒ
                - âš¡ **4.5ç§’å®Œæˆè®­ç»ƒ**: LoRAé«˜æ•ˆè®­ç»ƒéªŒè¯
                - ğŸ‡¨ğŸ‡³ **Qwen-1.8BæˆåŠŸ**: é˜¿é‡Œäº‘ä¸­æ–‡æ¨¡å‹å®Œç¾é›†æˆ
                - ğŸ“Š **6.3MBé€‚é…å™¨**: æé«˜å­˜å‚¨æ•ˆç‡
                - ğŸªŸ **Windows 11å…¼å®¹**: å®Œç¾ç¯å¢ƒæ”¯æŒ
                
                ### ğŸ”— GitHubé¡¹ç›®
                - **é¡¹ç›®åœ°å€**: https://github.com/roclee2692/Chinese-LLM-LoRA-Finetuning
                - **é¡¹ç›®çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
                - **å¼€æºè®¸å¯**: MIT License
                
                ### ğŸ“Š æŠ€æœ¯æŒ‡æ ‡
                - **è®­ç»ƒæ—¶é—´**: 4.536ç§’
                - **è®­ç»ƒæ­¥æ•°**: 10æ­¥
                - **æ ·æœ¬æ•°é‡**: 200ä¸ª
                - **å‚æ•°æ•ˆç‡**: ä»…è®­ç»ƒ0.36%å‚æ•°
                - **é€‚é…å™¨å¤§å°**: 6.3MB
                """)
        
        gr.HTML("""
        <div style="text-align: center; padding: 20px; color: #666;">
            <p>ğŸ‰ é¡¹ç›®å®Œå…¨æˆåŠŸï¼å¦‚æœè§‰å¾—æœ‰ç”¨ï¼Œè¯·ç»™é¡¹ç›®ç‚¹ä¸ªStarï¼</p>
        </div>
        """)
    
    return demo

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆWebæ¼”ç¤ºç•Œé¢...")
    print("ğŸ”— è®¿é—®åœ°å€: http://localhost:7862")
    
    demo = create_demo()
    demo.launch(
        server_name="127.0.0.1",  # åªå…è®¸æœ¬åœ°è®¿é—®
        server_port=7862,         # ä½¿ç”¨7862ç«¯å£
        share=False,
        inbrowser=False,          # ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
        show_error=True,
        check_update=False        # ä¸æ£€æŸ¥æ›´æ–°
    )